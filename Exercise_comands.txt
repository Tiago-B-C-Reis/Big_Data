GROUP 1 - HDFS
-----------------------------------------------------------------------------------------------------------------------------------------
docker exec -it hadoop-namenode bash

1:
hadoop fs -ls /user

2:
hadoop fs -mkdir /user/hdfs_practice


3.
exit
docker cp "/Users/tiagoreis/Downloads/01_HDFS.pdf" hadoop-namenode:/tmp
docker exec -it hadoop-namenode bash
hadoop fs -copyFromLocal "/tmp/01_HDFS.pdf" /user/hdfs_practice/

4.
hadoop fs -ls /user/hdfs_practice/01_HDFS.pdf

5.
hadoop fs -setrep 6 /user/hdfs_practice/01_HDFS.pdf
hadoop fs -ls /user/hdfs_practice/01_HDFS.pdf

6.
exit
docker cp "/Users/tiagoreis/Downloads/Tutorial_Hadoop_Installation_Docker.pdf" hadoop-namenode:/tmp
docker exec -it hadoop-namenode bash
hadoop fs -copyFromLocal "/tmp/Tutorial_Hadoop_Installation_Docker.pdf" /user/hdfs_practice/
hadoop fs -chmod -r /user/hdfs_practice/Tutorial_Hadoop_Installation_Docker.pdf
hadoop fs -ls /user/hdfs_practice/Tutorial_Hadoop_Installation_Docker.pdf

7. (Since I'm using hadoop on docker, I was ot able to see the disk usage of the file itself and the file with the replications)
hadoop fs -du -s -h /user/hdfs_practice
hadoop fs -du -s -h /user/hdfs_practice/01_HDFS.pdf
hadoop fs -du -s -h /user/hdfs_practice/Tutorial_Hadoop_Installation_Docker.pdf

8.
hadoop fs -cat /user/hdfs_practice/01_HDFS.pdf
hadoop fs -tail /user/hdfs_practice/01_HDFS.pdf
hadoop fs -text /user/hdfs_practice/01_HDFS.pdf

9.
hadoop fs -rm /user/hdfs_practice/01_HDFS.pdf
hadoop fs -ls /user/hdfs_practice

10.
hadoop fs -copyToLocal /user/hdfs_practice/Tutorial_Hadoop_Installation_Docker.pdf hadoop-namenode:/tmp
exit
docker cp hadoop-namenode:/tmp "/Users/tiagoreis/Downloads"

11.
"myfileA.txt" will only create the file on the local file system of that specific node (in this case, node 5).
To make the file available to the entire Hadoop cluster, it needs to be copied to HDFS (Hadoop Distributed File System),
which is the distributed file system used by Hadoop.

(hadoop fs -copyFromLocal myfileA.txt <hdfs_destination>)

Once the "myfileA.txt" is in the HDFS, it becomes accessible to the entire cluster,
and it can be manipulated from any node in the cluster using HDFS commands.





GROUP 2 - WordCount
-----------------------------------------------------------------------------------------------------------------------------------------
Ex:1 -----------------------------------------------------
# Compile:
javac -cp "./*" WordCount.java    

# Generate the jar file:
jar cvf WordCount.jar *.class

hadoop fs -mkdir /user/input

hadoop fs -copyFromLocal "/tmp/hotel_bookings.csv" /user/input/
hadoop fs -copyFromLocal "/tmp/iris.csv" /user/input/
hadoop fs -copyFromLocal "/tmp/NetflixOriginals.csv" /user/input/
hadoop fs -copyFromLocal "/tmp/student_math_clean.csv" /user/input/
hadoop fs -copyFromLocal "/tmp/student_portuguese_clean.csv" /user/input/

hadoop fs -rm /user/input/hotel_bookings.csv
hadoop fs -rm /user/input/WordCount.jar
hadoop fs -rm /user/input/NetflixOriginals.csv
hadoop fs -rm /user/input/student_math_clean.csv
hadoop fs -rm /user/input/student_portuguese_clean.csv

hadoop fs -rm -r /user/output

hadoop jar WordCount.jar WordCount /user/input /user/output

hadoop fs -cat /user/output/part-r-00000


Ex:2 -----------------------------------------------------
# Compile: (run inside the docker container)
javac -cp "./*" WordCategorizer.java

# Generate the jar file: (run inside the docker container)
jar cvf WordCategorizer.jar *.class

# Use "WordCategorizer.jar" to run "WordCounter" to categorize the words inside "iris.csv":
cd tmp
hadoop jar WordCategorizer.jar WordCategorizer /user/input /user/output_1

# Read the output:
hadoop fs -cat /user/output_1/part-r-00000


Ex: 3 -----------------------------------------------------
# Compile: (run inside the docker container)
javac -cp "./*" IrisClassCount.java

# Generate the jar file: (run inside the docker container)
jar cvf IrisClassCount.jar *.class

# Use "IrisClassCount.jar" to run "WordCounter" to categorize the words inside "iris.csv":
cd tmp
hadoop jar IrisClassCount.jar IrisClassCount /user/input /user/output_2

# Read the output:
hadoop fs -cat /user/output_2/part-r-00000





GROUP 3 - Hive
-----------------------------------------------------------------------------------------------------------------------------------------
Start-up:
docker exec -it hadoop-hive-server bash
beeline -u jdbc:hive2://localhost:10000

Ex_1: -----------------------------------------------------
CREATE TABLE stud_math(
    student_id INT,
    age INT,
    travel_time STRING,
    study_time STRING,
    absences INT,
    grade_1 DOUBLE,
    grade_2 DOUBLE,
    final_grade DOUBLE,
    address_type STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;


# EX:2 - load dataset -----------------------------------------------------
docker cp "/Users/tiagoreis/Documents/student_math_clean.csv" hadoop-hive-server:/tmp
docker exec -it hadoop-hive-server bash
hadoop fs -copyFromLocal "/tmp/student_math_clean.csv" /tmp
hadoop fs -mkdir /user/data/staging/math_st
hadoop fs -put /tmp/student_math_clean.csv /user
beeline -u jdbc:hive2://localhost:10000
LOAD DATA INPATH '/user/student_math_clean.csv' INTO TABLE stud_math;


# EX:3 -----------------------------------------------------
SELECT 
    COUNT(*) AS row_counter
FROM stud_math;

SELECT * 
FROM stud_math 
LIMIT 10;


# EX:5 -----------------------------------------------------
docker cp "/Users/tiagoreis/Documents/student_portuguese_clean.csv" hadoop-hive-server:/tmp
docker exec -it hadoop-hive-server bash
hadoop fs -copyFromLocal "/tmp/student_portuguese_clean.csv" /tmp
hadoop fs -mkdir /user/data/staging/portuguese_st
beeline -u jdbc:hive2://localhost:10000

CREATE EXTERNAL TABLE stud_portuguese(
    student_id INT,
    age INT,
    travel_time STRING,
    study_time STRING,
    absences INT,
    grade_1 DOUBLE,
    grade_2 DOUBLE,
    final_grade DOUBLE,
    address_type STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE
LOCATION '/user/data/staging/portuguese_st'
TBLPROPERTIES ("skip.header.line.count"="1");

QUIT Hive

hadoop fs -put /tmp/student_portuguese_clean.csv /user/data/staging/portuguese_st
beeline -u jdbc:hive2://localhost:10000

# EX:6 -----------------------------------------------------
SELECT 
    COUNT(*) AS row_counter
FROM stud_portuguese;

SELECT * 
FROM stud_portuguese 
LIMIT 10;


Querying
# EX:7 -----------------------------------------------------
How many students have been approved in math and Portuguese (considering final_grade > 10)?
    SELECT count(*) AS approved_students
    FROM stud_math
    WHERE final_grade > 10;

# EX:8 -----------------------------------------------------
What is the final_grade average per age in math?
    SELECT age, AVG(final_grade) AS average_final_grade
    FROM stud_math
    GROUP BY age;


# EX:9 -----------------------------------------------------
What are the top 10 Portuguese?
    SELECT student_id, final_grade
    FROM stud_math
    ORDER BY final_grade DESC
    LIMIT 10;

# EX:10 -----------------------------------------------------
Write a query to join from both tables using the studing_id (limit the results to 10 rows) and returning id, age, 
travel_time, math final grade, portuguese final grade and the final grades average (sum math and portuguese grades and divide by 2).

SELECT 
    A.student_id AS student_id,
    A.age AS age,
    A.travel_time AS travel_time,
    COALESCE((A.grade_1 + A.grade_2) / 2, 0) AS math_final_grade, 
    COALESCE((B.grade_1 + B.grade_2) / 2, 0) AS portuguese_final_grade,
    COALESCE((A.grade_1 + A.grade_2 + B.grade_1 + B.grade_2) / 4, 0) AS final_grade
FROM stud_math A
LEFT JOIN stud_portuguese B ON A.student_id = B.student_id
LIMIT 10;


Partitioning
# EX:11 -----------------------------------------------------
Create a new table (non-external) final_students partitioned by year, it should contain: 
studing_id, age, travel_time, math_final_grade, portuguese_final_grade and final_grade

CREATE TABLE final_students(
    student_id INT,
    age INT,
    travel_time STRING,
    math_final_grade DOUBLE,
    portuguese_final_grade DOUBLE,
    final_grade DOUBLE
)
PARTITIONED BY (year INT)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;


# EX:12 -----------------------------------------------------
Load data into the new table using the results of the step 10 query

SET hive.exec.dynamic.partition.mode=nonstrict;

INSERT INTO TABLE final_students PARTITION (year)
SELECT
    A.student_id AS student_id,
    A.age AS age,
    A.travel_time AS travel_time,
    COALESCE((A.grade_1 + A.grade_2) / 2, 0) AS math_final_grade,
    COALESCE((B.grade_1 + B.grade_2) / 2, 0) AS portuguese_final_grade,
    COALESCE((A.grade_1 + A.grade_2 + B.grade_1 + B.grade_2) / 4, 0) AS final_grade,
    CASE
        WHEN COALESCE((A.grade_1 + A.grade_2 + B.grade_1 + B.grade_2) / 4, 0) >= 10 THEN 1  -- 10 is the passing grade
        ELSE 0
    END AS year
FROM stud_math A
LEFT JOIN stud_portuguese B ON A.student_id = B.student_id;


# EX:13 -----------------------------------------------------
Check again the results doing some simple queries, such as 
SELECT COUNT(*) and SELECT * FROM ... LIMIT 10. Do you see something different in terms of sorting if we compare it with the results we have seen so far?

SELECT * 
FROM final_students 
LIMIT 10;

SELECT COUNT(*) AS rows_counter
FROM final_students;


# EX:14 -----------------------------------------------------
Check the folder /user/hive/warehouse/ to see the folders the hive uses to storage the data, and explore how hive splits the partitions.



FALTA PRINT AO EXERCICIO 6!!!!!
